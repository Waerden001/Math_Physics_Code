{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handle Special functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBPBBzI2wjb3",
        "colab_type": "text"
      },
      "source": [
        "# From special functions to the idea of the Physics_Mathematics_Code project\n",
        "\n",
        "To deal with special functions in practice, we always need the following knowledge,\n",
        "- **Transform property** (Group action, change of variables)\n",
        "- **Fourier transform and related inner product formulas**(The transition matrix and the invariant properties. In a very general sense, Mellien transform, Abel transform all fall in this category.)\n",
        "- **Local properties** (Estimation, Taylor expansion and Asymptotics, residues)\n",
        "\n",
        "However, the problem is that, we find **it's hard and nearly pointless to memorize all those induced formulas**, for example\n",
        "\n",
        "$$\\frac{1}{2\\pi i}\\int_{c-i\\infty}^{c+i\\infty}\\Gamma\\left(s+a\\right)\\Gamma\\left\n",
        "(b-s\\right)z^{-s}\\mathrm{d}s=\\frac{\\Gamma\\left(a+b\\right)z^{a}}{(1+z)^{a+b}}.$$\n",
        "\n",
        "What we should understand or \"memorize\" is where does it come from and how to use it in practice. \n",
        "\n",
        "- It comes from the simple general fact that **\"Fourier transforms preserve the inner product\"**, two sides are basically two ways of computing the inner product. For the Gamma integral above, it come from **the Parseval formula for the Mellien transform** (that is Fourier transform preserves the inner product)\n",
        "---\n",
        "(Parseval formula) $\\displaystyle \\int_{0}^{\\infty}f(x)g(x)dx=\\frac{1}{2\\pi i}\\int_{c-i\\infty}^{c+i\\infty}M[f, 1-s]M[g, s]ds$\n",
        "\n",
        "(Facts) Let $f(x)=x^{a}e^{-x}$, and $g(x)=z^{-b}x^{b-1}e^{-\\frac{x}{z}}$. Then\n",
        "$$M[f,s]=\\Gamma(s+a), M[g,s]=z^{s-1}\\Gamma(s+b-1).$$ \n",
        "\n",
        "Apply Parseval formula on $f(x)$ and $g(x)$ we get the integral formula above.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzG7QZF50oTB",
        "colab_type": "text"
      },
      "source": [
        "# What's the point?\n",
        "\n",
        "Our point is that, as mortal men, maybe **we don't want to memorize** things like\n",
        "- The exact form of the Parseval formula. (Conditions on functions, shifts on parameters, constants for normalization, when we know too many this kinds of formulae, it's simply impossible (at least for the author) and unnecessary to memorize those details, **this doesn't mean details are not important**, in fact, they are important. But as long as they're facts that are not hard to find, we should reserve our limited brains for more important things, like, what do we actually understand?)\n",
        "- The Gamma integral formula. (Trigonometric formulas are fine, but do you want to remember those transformation and integral formulas for hypergeometric functions? Maybe it's just I'm being too lazy?)\n",
        "\n",
        "However, we do need to remember things like\n",
        "\n",
        "- Understand why things like this are true. (Fourier transform preserves the inner product simply because we're computing the same trace with two different sets of basis, Mellin transform is just a Fourier transform on a strip).\n",
        "- Where to find those exact formulas easily and work with them. (**DLMS(Digital library of mathematical functions 15.13, Wolfram Alpha** for example)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQldo0WX3Ewz",
        "colab_type": "text"
      },
      "source": [
        "# But how to realize our goal\n",
        "Our goal has two aspects\n",
        "1. Understand why something is true.\n",
        "2. Find out any detail and work with it as long as we want to.\n",
        "\n",
        "Surely, a straightforward way is to\n",
        "- Spend time understanding things. (Note that **proof is not understanding**)\n",
        "- Find/build tools/repository that makes it easy to store and recall any detail(about the formulae themselves, about tedious computations, or about the proof). \n",
        "\n",
        "## **Tools part**\n",
        "- Softwares. (Sagemath, Macaulay2, Wolfram Language/Mathematica, etc)\n",
        "- Databases. (DLMF, LMFDB(L-functions and modular forms database), Harmonic analysis database that we're trying to build).\n",
        "- Layered references. (Documentation, implementations, API and source code).\n",
        "\n",
        "Let me explain a little bit what do they mean. \n",
        "\n",
        "### Softwares\n",
        "\n",
        "Softwares are important for us to carry out some real computations, for example, seeing rows of 0.999999...'s or a curve gose to $1$ feels very different from just writing down the Weyl's law for a sphere. In our point of view, only after we figuring out and computing examples in the very details, we can actually say, **maybe** we finally understand something. It's hard to explain but easy to feel, we have tons of examples, like, knowing the statement/name of a trace formula (Selberg, Arthur, etc) is very different form knowing the trace formula itself, you have to at least figure it out for $GL(2, \\mathbf{F}_{q})$ and get every term right to actually get a feeling about the power/beauty of the theorem. We can also put it in this way, we can buy expensive guitars everyday, but if you don't put your hands on it everyday, and figure out every inch of the fretboard, there's no way you can improvise and express yourself freely.  \n",
        "\n",
        "### Database\n",
        "\n",
        "Traditional databases like DLMF or LMFDB or knowledge-based databases like Wolfram Alpha, are like **documentation** for a library, they're good places to find out correct ways to call a function, namely, what/how many parameters do we need in the input, what kind of results should we expect to get.  **However, nobody wants to read the source code directly in the documentation**. One thing good about the organizations in the programming/CS world is that if we want to find out details of the implementations (kind of like proofs or \"tedious\" computations), we only need a few clicks/hang-vers, in math, however, we basically have to go through all those go-to style references and follow hundreds if not thousands of equations labels and then just find more references to other books and only to realize we've carried too much unnecessary details along the way and get trapped and frustrated. \n",
        "\n",
        "### Layered references \n",
        "\n",
        "Like on Github, if we click on a function, we find out the implementation details directly, this implementation might contains other functions, it depends on us if we want to click on any of those further functions. But if we don't, the skeleton of the current function should be quite clear, which means things are layered, we can chose to go to which layer, instead of following a math book only to take too many nonessentail details with us on the way to understand one \"function\". Once we point to somewhere else, the details disappear automatically from our sight. We've had the following silly thoughts about where we might want layered references,\n",
        "- Stacks project, in our point of view, is like all the source code for algebraic geometry, which is very nice that we have one. However, we might not want to see all the details and all the general statements and formulae and related obscure algebraic statements. A better way (in our arrogant point of view) is to separate it into two parts: the library/documentation and the source code. That is, the user interface should only contain documentation-like information, for example, how to apply a trick, lemma, theorem correctly. On the other hand, the source code/implementation part contains details of proofs, references, computations. Moreover, the proofs should be layered in the sense that a proof should try to highlight the most essential point for the current statement and hide uncessary ones (which usually obscures the main point).\n",
        "\n",
        "- DLMF is a very good example of **Mathematical documentation** of special functions. However, the references are very much math-style, we still have to download the papers, books and follow \"thousands\" of self-pointers in the references to glue a complete proof of one statement in the documentation. We'd like to see in the future, we only need to click on the statement in the documentation and find out the \"implementation of the statement\". \n",
        "\n",
        "**The most important reason that explains all our fantasies above is that after all these we can actually focus on understanding things and discovering connections.**\n",
        "\n",
        "Labor works and skills are important, but they're tools not our ultimate goal. Since they're only tools, why don't we **mordernize** them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPITuwLhzI24",
        "colab_type": "text"
      },
      "source": [
        "# More\n",
        "\n",
        "4/14/2020\n",
        "\n",
        "We spend the whole day play with various *Wolfram softwares* and we find this problem: **As human beings, we have the freedom to manipulate a symbolic expression totally formally and we tolerate certain degree of ambiguity, and after a certain point, we do symbolic computations in a rigorious way, and get numberical results in the end if we want. For softwares, the whole thing is not that natural**\n",
        "- Formal manipulation $\\neq$ symbolic computation. \n",
        "- Every term has to be well-defined anytime and anywhere in the software. Even if they're just symbols.\n",
        "- Not always possible to see intermediate steps.\n",
        "- Most softwares/languages are not formal or symbolic enough.\n",
        "\n",
        "Let me use one example to show what I mean, in Bump's short paper *Barnes' Second Lemma and its Application to Rankin-Selberg Convolutions*, we basically only need to compute several integrals via Mellin transform and Barnes' second lemma. With the help of Wolfram, it's very easy to check that\n",
        "$$\\int_{0}^{\\infty}K_{n}(x)x^{s-1}dx=2^{s-2}\\Gamma(\\frac{s+n}{2})\\Gamma(\\frac{s-n}{2}),$$\n",
        "where $K_{n}(x)$ is the $n$-th modified Bessel function of the second kind. However, another class of special functions in the paper is defined to be\n",
        "$$K_{a,b,c}(x,y)=$$\n",
        "$$\\frac{1}{(2\\pi i)^2}\\int_{-i\\infty}^{+i\\infty}\\int_{-i\\infty}^{+i\\infty}\\frac{\\Gamma(\\frac{u+a}{2})\\Gamma(\\frac{u+b}{2})\\Gamma(\\frac{u+c}{2})\\Gamma(\\frac{v-a}{2})\\Gamma(\\frac{v-a}{b})\\Gamma(\\frac{v-c}{2})}{\\Gamma(\\frac{u+v}{2})}(\\frac{x}{2})^{-u}(\\frac{y}{2})^{-v}dudv$$\n",
        "which is basically a double inverse Mellin transform, if we try to realize this in Wolfram, the first inverse Mellin transform is already very complicated, and somehow, the software just doesn't compute the second inverse Mellin transfrom, it simply leaves it as how it is defined, if we try to check identity at the bottom of page 181 in the paper, the further Mellin transform still doesn't get simplified in the software, surely, it's very likely that it's my ignorance about the software. But it seems, at the current stage, it's simply impossible to avoid to tedious computations or manipulations, even if we can realize them in softwares, the confusions and frustrations are actually more than the tedious computations/manipulations themselves. This surely tells us having tools doesn't mean problems disappear magically, we might use our tools to \n",
        "\n",
        "- Recall knowledge.\n",
        "- Reorganize knowlege and keep record via notebooks.\n",
        "- Utilize well-supported operations: Mellin transform, Fourier transform on the real line.\n",
        "\n",
        "In the above example, it means\n",
        "- For Mellin transform, Inverse Mellin Transform, Gamma functions, Beta functions, Bessel functions, we don't need to remember every detail of them, instead, we should ask ourselves, what are those functions? when and where do they appear? How do we use them and in what ways can we manipulate them?\n",
        "- We recollect pieces of informations about those special functions and integral transforms together. If we write a notebook, it's always there, we only need to remember what we've done, we can find out all the details and necessary pieces of knowledge as long as want.\n",
        "- Don't reinvent the wheels, if we can identify the complicated double integral is a double Mellin transform, then we can use the well-implemented functions in the software to do tedious computations for us and even get intuitive graphs sometimes. But if we only view it as an integral, we have to parametrize the curve and make sure everything makes sense (like complex integrals, infinities,etc), which could be very daunting.  \n",
        "\n",
        "- More than often, we find the software gets stuck or just can't understand some simple facts like $TSS^{-1}T^{-1}f=f$, it literally computes all four operations and things actually become very complicated after the first two operations, even when we apply the inverse operation directly after the second operation, the software still computes based on the very complicated intermediate result, which makes it seemly impossible to see the simple fact. \n",
        "\n",
        "- On the other hand, it's very easy for the software to compute the Mellin transform of the Gamma function, of the normal distribution, or of the modified Bessel function, which are actually pretty hard (at least for me) to keep every detail right all the time, surely, it's also simply impossible for me to remember all those complicated and detail definitions and relations, parameters. However, it's very very easy for the computer.\n",
        "\n",
        "- In conclusion, maybe human beings should just focus on what we're good at: dealing with simple things, and let the computers do what they're good at: complicated computations and seemly unlimited memories.** However, we really need to work hard enough to really do our job well enough to the extent that the left-overs are actually very easy for the computers**, if we try to rely on the computers from the very begins, it's easy to get destryed by the **combined difficulties**-namely, we get frustrated by the weakness of the computers and the weakness of ourselves at the same time, which is even worse than we just do all the things ourselves without any computer's assistants. \n",
        "\n",
        "- In some sense, we have to be a good leader, we should have a bird's-eye view, we tell the story and hold the map, we know who's good at what. At the right time, at the right spot, we can find the right person/tool to get works done, instead of doing all and every task by ourselves, that's not how you run a company or finish a project."
      ]
    }
  ]
}